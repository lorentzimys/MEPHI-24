{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dcd0160-26ba-4f21-8d53-4752b4d67505",
   "metadata": {},
   "source": [
    "# Домашнее задание №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0bbd2",
   "metadata": {},
   "source": [
    "### Подготовка виртуального окружения Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58320412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444a488",
   "metadata": {},
   "source": [
    "### Генерация тренировочного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9fdd964-7987-4cb7-8ed7-cbcf7f84b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "634820cd-d106-48da-8a8d-0a349b55f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractMethods:\n",
    "    TF_IDF = 'tf-idf'\n",
    "    TF_IDF_NGRAM = 'tf-idf_ngram'\n",
    "    BAG_OF_WORDS = 'bag_of_words'\n",
    "    BAG_OF_CHAR = 'bag_of_characters'\n",
    "\n",
    "\n",
    "class FeatureExtractor:\n",
    "  def __init__(self, method, *args, **kwargs):\n",
    "    self.args = args\n",
    "    self.kwargs = kwargs\n",
    "    self.notes = {}\n",
    "    self.vectorizer = self._get_vectorizer(method)\n",
    "\n",
    "  def _get_vectorizer(self, method):\n",
    "    token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "    match method:\n",
    "      case ExtractMethods.TF_IDF:\n",
    "          return TfidfVectorizer(tokenizer=token.tokenize, lowercase=True, **self.kwargs)\n",
    "      case ExtractMethods.TF_IDF_NGRAM:\n",
    "          return TfidfVectorizer(lowercase=True, analyzer='char', ngram_range=(1, 3), **self.kwargs)\n",
    "      case ExtractMethods.BAG_OF_WORDS:\n",
    "          return CountVectorizer(analyzer='word', tokenizer=token.tokenize, lowercase=True, **self.kwargs)\n",
    "      case ExtractMethods.BAG_OF_CHAR:\n",
    "          return CountVectorizer(analyzer='char', lowercase=True, **self.kwargs)\n",
    "      case _:\n",
    "          raise ValueError(f\"Unknown feature extraction method: {method}\")\n",
    "\n",
    "  def fit_extract(self, x_train):\n",
    "      return self.vectorizer.fit_transform(x_train)\n",
    "\n",
    "  def extract_features(self, x):\n",
    "      return self.vectorizer.transform(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "494d0873-d166-4a60-8b43-71f8058ce824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd25dcd1-e0bd-4e76-b4e4-32bda0e72ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelecter:\n",
    "    def __init__(self, n_components):\n",
    "        self._scaler = StandardScaler(with_mean=False)\n",
    "        self._lasso_selecter = SelectFromModel(Lasso(alpha=0.001, random_state=10))\n",
    "        self._pca = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "    def _to_dense(self, X):\n",
    "        return X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "    def fit_transform(self, x_train, y_train):\n",
    "        self._scaler.fit(x_train)\n",
    "        Xs = self._scaler.transform(x_train)\n",
    "        Xs_dense = self._to_dense(Xs)\n",
    "        self._lasso_selecter.fit(Xs_dense, y_train)\n",
    "        Xsel = self._lasso_selecter.transform(Xs_dense)\n",
    "        self._pca.fit(Xsel)\n",
    "        return self._pca.transform(Xsel)\n",
    "    \n",
    "    def transform(self, x):\n",
    "        Xs = self._scaler.transform(x)\n",
    "        Xs_dense = self._to_dense(Xs)\n",
    "        Xsel = self._lasso_selecter.transform(Xs_dense)\n",
    "        return self._pca.transform(Xsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfdda3-38e7-4b26-81f1-c4e80c43c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df89125-3df1-4133-a3ce-e6bb969ecec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models:\n",
    "    XGBOOST = 'XGBoost'\n",
    "    SVC = 'SVC'\n",
    "    NU_SVC = 'NuSVC'\n",
    "    KNEIGHBORS = 'KNeighbors'\n",
    "    DECISION_TREE = 'DecisionTree'\n",
    "    RANDOM_FOREST = 'RandomForest'\n",
    "    ADABOOST = 'AdaBoost'\n",
    "    BAGGING = 'Bagging'\n",
    "    EXTRA_TREES = 'ExtraTrees'\n",
    "    LINEAR_SVC = 'LinearSVC'\n",
    "\n",
    "\n",
    "class ModelFabric:\n",
    "    @staticmethod\n",
    "    def create_model(model_name, *args, **kwargs):\n",
    "        match model_name:\n",
    "            case Models.XGBOOST:\n",
    "                return xgb.XGBClassifier(*args, **kwargs)\n",
    "            case Models.SVC:\n",
    "                return SVC(gamma=2, C=1, *args, **kwargs)\n",
    "            case Models.NU_SVC:\n",
    "                return NuSVC(*args, **kwargs)\n",
    "            case Models.KNEIGHBORS:\n",
    "                return KNeighborsClassifier(3, *args, **kwargs)\n",
    "            case Models.DECISION_TREE:\n",
    "                return DecisionTreeClassifier(max_depth=5, *args, **kwargs)\n",
    "            case Models.RANDOM_FOREST:\n",
    "                return RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, *args, **kwargs)\n",
    "            case Models.ADABOOST:\n",
    "                return AdaBoostClassifier( *args, **kwargs)\n",
    "            case Models.BAGGING:\n",
    "                return BaggingClassifier(*args, **kwargs)\n",
    "            case Models.EXTRA_TREES:\n",
    "                return ExtraTreesClassifier(*args, **kwargs)\n",
    "            case Models.LINEAR_SVC:\n",
    "                return LinearSVC(*args, **kwargs)\n",
    "            case _:\n",
    "                raise ValueError(f\"Unsupported model name: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b40ea304-727d-4bd1-9c5f-937d6d4fde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_expect, y_pred):\n",
    "    cm = confusion_matrix(y_expect, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', xticklabels=['Normal','SQL-Injection'], yticklabels=['Normal','SQL-Injection'])\n",
    "    plt.xlabel('Prediction',fontsize=13)\n",
    "    plt.ylabel('Actual',fontsize=13)\n",
    "    plt.title('Confusion Matrix',fontsize=17)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "626f155b-cfe8-4f6e-ae7e-e26f03e7844a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m source_df = pd.read_csv(\u001b[43mTRAIN_FILE\u001b[49m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, engine=\u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m df_train, df_test = train_test_split(source_df, test_size=\u001b[32m0.3\u001b[39m, stratify=source_df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m], random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      3\u001b[39m x_train, y_train = df_train[\u001b[33m'\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m'\u001b[39m].values, df_train[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].values\n",
      "\u001b[31mNameError\u001b[39m: name 'TRAIN_FILE' is not defined"
     ]
    }
   ],
   "source": [
    "source_df = pd.read_csv(TRAIN_FILE, sep='\\t', engine='python')\n",
    "df_train, df_test = train_test_split(source_df, test_size=0.3, stratify=source_df['label'], random_state=42)\n",
    "x_train, y_train = df_train['payload'].values, df_train['label'].values\n",
    "x_test, y_test = df_test['payload'].values, df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e35bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры задания\n",
    "STUDENT_NAME = \"<Введите_Фамилию_Латиницей>\"  # например, \"Ivanov\"\n",
    "TRAIN_FILE = f\"{STUDENT_NAME}_dataset.tsv\"\n",
    "VALIDATE_FILE = \"validate.tsv\"\n",
    "SUBMISSION_FILE = f\"submission_{STUDENT_NAME}.csv\"\n",
    "\n",
    "# Проверим наличие тренировочного датасета; если его нет — создайте через create_task_dataset.py\n",
    "from pathlib import Path\n",
    "if not Path(TRAIN_FILE).exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Файл {TRAIN_FILE} не найден. Сначала выполните: python3 create_task_dataset.py --student_name {STUDENT_NAME} --file malicious.tsv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эксперименты: различные способы извлечения признаков и модели\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "extract_setups = [\n",
    "    (ExtractMethods.TF_IDF, {\"lowercase\": True}),\n",
    "    (ExtractMethods.TF_IDF_NGRAM, {}),\n",
    "    (ExtractMethods.BAG_OF_WORDS, {\"lowercase\": True}),\n",
    "]\n",
    "\n",
    "model_setups = [\n",
    "    Models.LINEAR_SVC,\n",
    "    Models.RANDOM_FOREST,\n",
    "    Models.XGBOOST,\n",
    "]\n",
    "\n",
    "results = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for extract_method, kwargs in extract_setups:\n",
    "    fe = FeatureExtractor(extract_method, **kwargs)\n",
    "    Xtr = fe.fit_extract(x_train)\n",
    "    selector = FeatureSelecter(n_components=min(100, Xtr.shape[1]-1) if Xtr.shape[1] > 1 else 1)\n",
    "    Xtr_sel = selector.fit_transform(Xtr, y_train)\n",
    "\n",
    "    for model_name in model_setups:\n",
    "        model = ModelFabric.create_model(model_name)\n",
    "        scores = cross_val_score(model, Xtr_sel, y_train, cv=skf, scoring=\"accuracy\", n_jobs=None)\n",
    "        results.append({\n",
    "            \"extract\": extract_method,\n",
    "            \"model\": model_name,\n",
    "            \"cv_mean\": float(np.mean(scores)),\n",
    "            \"cv_std\": float(np.std(scores))\n",
    "        })\n",
    "\n",
    "pd.DataFrame(results).sort_values([\"cv_mean\", \"cv_std\"], ascending=[False, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение лучшей связки на train и оценка на test + confusion matrix\n",
    "# Вы можете вручную выбрать лучшую пару из таблицы выше. По умолчанию берём TF-IDF + LinearSVC\n",
    "best_extract_method = ExtractMethods.TF_IDF\n",
    "best_extract_kwargs = {\"lowercase\": True}\n",
    "best_model_name = Models.LINEAR_SVC\n",
    "\n",
    "fe_best = FeatureExtractor(best_extract_method, **best_extract_kwargs)\n",
    "Xtr_full = fe_best.fit_extract(x_train)\n",
    "selector_best = FeatureSelecter(n_components=min(100, Xtr_full.shape[1]-1) if Xtr_full.shape[1] > 1 else 1)\n",
    "Xtr_sel_full = selector_best.fit_transform(Xtr_full, y_train)\n",
    "\n",
    "model_best = ModelFabric.create_model(best_model_name)\n",
    "model_best.fit(Xtr_sel_full, y_train)\n",
    "\n",
    "# Оценка на holdout-тесте\n",
    "Xte = fe_best.extract_features(x_test)\n",
    "Xte_sel = selector_best.transform(Xte)\n",
    "y_pred = model_best.predict(Xte_sel)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "plot_confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение на всём тренировочном датасете и предсказание для validate.tsv\n",
    "# Перевычим на всём source_df\n",
    "fe_final = FeatureExtractor(best_extract_method, **best_extract_kwargs)\n",
    "X_all = fe_final.fit_extract(source_df['payload'].values)\n",
    "selector_final = FeatureSelecter(n_components=min(100, X_all.shape[1]-1) if X_all.shape[1] > 1 else 1)\n",
    "X_all_sel = selector_final.fit_transform(X_all, source_df['label'].values)\n",
    "\n",
    "final_model = ModelFabric.create_model(best_model_name)\n",
    "final_model.fit(X_all_sel, source_df['label'].values)\n",
    "\n",
    "# Предсказание\n",
    "validate_df = pd.read_csv(VALIDATE_FILE, sep='\\t', engine='python')\n",
    "X_val = fe_final.extract_features(validate_df['payload'].values)\n",
    "X_val_sel = selector_final.transform(X_val)\n",
    "val_pred = final_model.predict(X_val_sel)\n",
    "\n",
    "# Сохранение сабмишена\n",
    "submission = pd.DataFrame({\n",
    "    'ID': validate_df['ID'],\n",
    "    'TARGET': val_pred\n",
    "})\n",
    "submission.to_csv(SUBMISSION_FILE, index=False)\n",
    "print(f\"Saved submission to: {SUBMISSION_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b928198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовое исследование данных\n",
    "display(source_df.head())\n",
    "print(source_df.info())\n",
    "print(source_df.describe(include='all'))\n",
    "print(\"Пропуски по столбцам:\\n\", source_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5c436",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5850d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100f0f8",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
